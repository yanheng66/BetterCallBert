# build_knowledge.py
# -----------------------------------------------------------
# åŠŸèƒ½ï¼šè¯»å–æ³•è§„ PDF â†’ æ„å»ºæ··åˆæ£€ç´¢ç´¢å¼• â†’ NLP æ‰©å……æŸ¥è¯¢ â†’ æ£€ç´¢ â†’
#      å°†ä¸Šä¸‹æ–‡äº¤ç»™ LLM ç”Ÿæˆæ³•å¾‹ä¸“ä¸šå›ç­”
# -----------------------------------------------------------

from pathlib import Path
from knowledge.loader import load_pdf_text, extract_text_from_images
from knowledge.index_builder import build_index
from knowledge.retriever import get_hybrid_retriever
from knowledge import init_environment

from nlp.nlp_pipeline import LegalNLPPipeline          # â˜… æ–°å¢ï¼šå¼•å…¥ NLP ç®¡é“
from llama_index.core.prompts import PromptTemplate
from llama_index.core.llms import ChatResponse
from llama_index.core import Settings

# ======== å…¨å±€é…ç½® ========
PDF_PATH = "./data/uscode-title23.pdf"   # ç¤ºä¾‹ï¼šç¾å›½è”é‚¦æ³•å…¸ Title 23
USE_OCR  = True                          # True â†’ PDF è½¬å›¾ç‰‡å OCRï¼›False â†’ ç›´æ¥è¯»å–æ–‡æœ¬
TOP_K    = 5                             # æ£€ç´¢è¿”å›çš„æ®µè½æ•°é‡

# ======== åˆå§‹åŒ–ç¯å¢ƒ ========
init_environment()                       # OpenRouter LLM + LoRA åµŒå…¥æ¨¡å‹
nlp_pipeline = LegalNLPPipeline()        # NLP ç®¡é“ï¼ˆåˆ†ç±» / å…³é”®è¯ / å®ä½“ï¼‰

# -----------------------------------------------------------
# å‡½æ•°ï¼šç”¨ NLP ç»“æœæ‰©å……æŸ¥è¯¢ï¼ˆQuery Expansionï¼‰
# -----------------------------------------------------------
def expand_query(question: str) -> str:
    """
    å°† NLP æå–çš„å…³é”®è¯å’Œå®ä½“ä¸åŸé—®é¢˜æ‹¼æ¥ï¼Œæå‡æ£€ç´¢å¬å›ç‡
    """
    analysis  = nlp_pipeline.analyze(question)
    keywords  = analysis["keywords"]                     # KeyBERT å…³é”®è¯
    entities  = [txt for txt, _ in analysis["entities"]] # spaCy å®ä½“æ–‡æœ¬

    # å»é‡åç»„æˆé¢å¤–æŸ¥è¯¢è¯
    extra_terms = list(dict.fromkeys(keywords + entities))
    # è¿”å›â€œåŸå§‹é—®é¢˜ + å…³é”®è¯ + å®ä½“â€çš„åˆå¹¶å­—ç¬¦ä¸²
    return " ".join([question] + extra_terms)

# -----------------------------------------------------------
# å‡½æ•°ï¼šå°†æ£€ç´¢ä¸Šä¸‹æ–‡ä¸é—®é¢˜æ‹¼æ¥ï¼Œäº¤ç»™ LLM è·å–æœ€ç»ˆå›ç­”
# -----------------------------------------------------------
def answer_question(llm, question: str, contexts):
    context_text = "\n\n".join([r.node.get_content() for r in contexts])

    prompt = PromptTemplate(
        "You are a legal assistant. Based on the following legal context, answer the question:\n\n"
        "Context:\n{context}\n\n"
        "Question:\n{question}\n\n"
        "Answer in clear legal English:"
    )
    full_prompt = prompt.format(context=context_text, question=question)
    response: ChatResponse = llm.complete(full_prompt)
    return response.text.strip()

# -----------------------------------------------------------
# ä¸»æµç¨‹
# -----------------------------------------------------------
def main():
    # 1) è¯»å–/è§£æ PDF
    if USE_OCR:
        documents = [extract_text_from_images(PDF_PATH)]
    else:
        documents = load_pdf_text(PDF_PATH)

    # 2) æ„å»ºç´¢å¼• & æ£€ç´¢å™¨
    index, nodes = build_index(documents)
    retriever    = get_hybrid_retriever(index, nodes)

    # 3) ç”¨æˆ·æé—®
    question = "What is the definition of 'construction' under Title 23?"  # ç¤ºä¾‹é—®é¢˜

    # 4) æ‰©å……æŸ¥è¯¢å¹¶æ£€ç´¢
    expanded_query = expand_query(question)
    results        = retriever.retrieve(expanded_query)[:TOP_K]

    print(f"\nğŸ“„ æ£€ç´¢ç»“æœï¼ˆTop {TOP_K}ï¼‰ï¼š")
    for i, r in enumerate(results):
        snippet = r.node.get_content()[:300].replace("\n", " ")
        print(f"\nResult {i+1} (Score: {r.score:.4f}): {snippet} ...")

    # 5) äº¤ç»™ LLM ç”Ÿæˆæœ€ç»ˆå›ç­”
    answer = answer_question(Settings.llm, question, results)
    print("\nğŸ§  AI å›ç­”ï¼š\n", answer)

# -----------------------------------------------------------
# è„šæœ¬å…¥å£
# -----------------------------------------------------------
if __name__ == "__main__":
    main()
